# EDTER
> [EDTER: Edge Detection with Transformer](https://arxiv.org/abs/2203.08566)                 
> Mengyang Pu, Yaping Huang, Yuming Liu, Qingji Guan and Haibin Ling                 
> *CVPR 2022*

Please refer to [supplementary material](https://github.com/MengyangPu/EDTER/blob/main/supp/EDTER-supp.pdf) for more results.

## Contents
```
0 Issues
1 Usage
    1.1 Linux
    1.2 Datasets
    1.3 Initial weights
2 Traning
    2.1 Step1: The training of EDTER-Stage I on BSDS500
    2.2 Step2: The training of EDTER-Stage II on BSDS500
    2.3 How to train the EDTER model on BSDS-VOC (BSDS500 and PASCAL VOC Context):
        Step 1: The training of EDTER-VOC-Stage I on PASCAL VOC Context
    2.4 Step2: The training of EDTER-VOC-Stage I on BSDS500
    2.5 Step3: The training of EDTER-VOC-Stage II on BSDS500
3 Testing
    3.1 EDTER-Stage I with single-scale testing
    3.2 EDTER-Stage I with multi-scale testing
    3.4 EDTER-Stage II with single-scale testing
    3.5 EDTER-Stage II with multi-scale testing
4 ðŸ”¥ðŸ”¥The original results v.s. The reproduced resultsðŸ”¥ðŸ”¥
    4.1 The results of EDTER-Stage I on BSDS500
    4.2 The results of EDTER-Stage II on BSDS500
    4.3 The EDTER model pre-trained on the PASCAL VOC Context dataset
    4.4 The results of EDTER-VOC-Stage I on BSDS500
    4.5 The results of EDTER-VOC-Stage II on BSDS500
5 Eval
6 Results
7 Download the Pre-trained model
8 Important notes
9 Acknowledgments
10 Reference
```
## Issues and Answers
**ðŸ”¥Q:** How to change batch_size?

**ðŸ”¥A:** **the batch size of training = samples_per_gpu * GPU_NUM**
If you want to set the batch size=9, please set *samples_per_gpu* in
https://github.com/MengyangPu/EDTER/blob/bbee219d5713a77aeec61c0f7fde93620cb02d60/configs/bsds/EDTER_BIMLA_320x320_80k_bsds_bs_8.py#L99
For example, *data = dict(samples_per_gpu=4)* means that each GPU can process 4 images. If training batch_size=8, please set samples_per_gpu=4 and GPU_NUM=2.

**ðŸ”¥Q:** KeyError: 'BSDSDataset is not in the dataset registry'.

**ðŸ”¥A:** 
```
cd EDTER
pip install -e .  # or "python setup.py develop"
pip install -r requirements/optional.txt
```

**ðŸ”¥Q:** Dataset download.

**ðŸ”¥A:** Please refer to 1.2 [Datasets](https://github.com/MengyangPu/EDTER/#12-datasets)

**ðŸ”¥ðŸ”¥Q:** Reproduced results.

**ðŸ”¥ðŸ”¥A:** Please refer to 4 [The original results v.s. The reproduced results]([https://github.com/MengyangPu/EDTER/#12-datasets](https://github.com/MengyangPu/EDTER/#4-the-original-results-vs-the-reproduced-results), and we upload all reproduced results on BaiDuNetdisk.
Note: The capacity of our Google Drive is limited, and all training files (including .log files, .mat files, .png files, and .pth files) for each model are approximately 20GB.
[EDTER-Stage I](https://github.com/MengyangPu/EDTER/#41-the-results-of-edter-stage-i-on-bsds500)
Download all results (~20GB) from [here](https://pan.baidu.com/s/158B9xct-J8nnOBGSPuotRA?pwd=nx35).

[EDTER-Stage II](https://github.com/MengyangPu/EDTER/#42-the-results-of-edter-stage-ii-on-bsds500)
Download all results (~20GB) from [here](https://pan.baidu.com/s/1JzlXAH8YnOEFiDncjSDZpA?pwd=mawm).

[EDTER-VOC-Stage I pre-train](https://github.com/MengyangPu/EDTER/#43-the-edter-model-pre-trained-on-the-pascal-voc-context-dataset)
Download all results (~20GB) from [here](https://pan.baidu.com/s/1SS62jBW-Qao7BQ3nXrDvYQ?pwd=dk5v).

[EDTER-VOC-Stage I](https://github.com/MengyangPu/EDTER/#44-the-results-of-edter-voc-stage-i-on-bsds500)
Download all results (~20GB) from [here](https://pan.baidu.com/s/15CIuL2r0fZckSifgNFanBw?pwd=iwwv).

[EDTER-VOC-Stage II](https://github.com/MengyangPu/EDTER/#45-the-results-of-edter-voc-stage-ii-on-bsds500)
Download all results (~20GB) from [here](https://pan.baidu.com/s/1LmgQiCiWKrwzEuog5BQ_ng?pwd=b9rm).


## 1 Usage
Our project is developed based on [MMsegmentation](https://github.com/open-mmlab/mmsegmentation). Please follow the official MMsegmentation [INSTALL.md](https://github.com/fudan-zvg/SETR/blob/main/docs/install.md) and [getting_started.md](https://github.com/fudan-zvg/SETR/blob/main/docs/getting_started.md) for installation and dataset preparation.

### 1.1 Linux
The full script for setting up EDTER with conda is following [here](https://github.com/fudan-zvg/SETR).
```
conda create -n edter python=3.7 -y
conda activate edter
conda install pytorch=1.6.0 torchvision cudatoolkit=10.1 -c pytorch -y
pip install mmcv-full==1.2.2 -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.6.0/index.html
cd EDTER
pip install -e .  # or "python setup.py develop"
pip install -r requirements/optional.txt
```

### 1.2 Datasets
#### BSDS500
Download the augmented BSDS500 data (1.2GB) from [here](https://vcl.ucsd.edu/hed/HED-BSDS.tar).<br/>
```
|-- data
    |-- BSDS
        |-- ImageSets
        |   |-- train_pair.txt
        |   |-- test.txt
        |   |-- pascal_train_pair.txt
        |-- train
        |   |-- aug_data
        |   |-- aug_data_scale_0.5
        |   |-- aug_data_scale_1.5
        |   |-- aug_gt
        |   |-- aug_gt_scale_0.5
        |   |-- aug_gt_scale_1.5
        |-- test
        |   |-- 2018.jpg
        ......
```

#### PASCAL VOC
Download the augmented PASCAL VOC data from [here](https://pan.baidu.com/s/1d9CTR9w1MTcVrBvG-WIIXw?pwd=83cv)
(Code:83cv).

```
|-- data
    |-- PASCAL
        |-- ImageSets
        |   |-- pascal_train_pair.txt
        |   |-- test.txt
        |-- aug_data
            |-- 0.0_0
            |   |-- 2008_000002.jpg
            ......
            |-- 0.0_1
            |   |-- 2008_000002.jpg
            ......
        |-- aug_gt
            |-- 0.0_0
            |   |-- 2008_000002.png
            ......
            |-- 0.0_1
            |   |-- 2008_000002. png
            ......
```

#### NYUD
Download the augmented NYUD data (~11GB) from [here](https://pan.baidu.com/s/1J5z6235tv1xef3HXTaqnKg?pwd=t2ce)(Code:t2ce).<br/>
```
|-- data
    |-- NYUD
        |-- ImageSets
        |   |-- hha-test.txt
        |   |-- hha-train.txt
        |   |-- image-test.txt
        |   |-- image-train.txt
        |-- train
            |-- GT
            |-- GT_05
            |-- GT_15
            |-- HHA
            |-- HHA_05
            |-- HHA_15
            |-- Images
            |-- Images_05
            |-- Images_15
        |-- test
            |-- HHA
            |   |-- img_5001.png
            ......
            |-- Images
            |   |-- img_5001.png
            ......
```


### 1.3 Initial weights
If you are unable to download due to network reasons, you can download the initial weights from [here](https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p16_384-83fb41ba.pth)(VIT-base-p16) and [here](https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_p16_384-b3be5167.pth)(VIT-large-p16).
The two .pth files of initial weights should be placed in the [folder](https://github.com/MengyangPu/EDTER/tree/main/pretrain).
```
|-- EDTER
    |-- pretrain
        |-- jx_vit_base_p16_384-83fb41ba.pth
        |-- jx_vit_large_p16_384-b3be5167.pth
```

## 2 Training 
<b><font color=Red> Note: Our project only supports distributed training on multiple GPUs on one machine or a single GPU on one machine. </font></b>
### 2.1 Step1: The training of EDTER-Stage I on BSDS500
If you want to set the batch size in each GPU, please refer to
https://github.com/MengyangPu/EDTER/blob/bbee219d5713a77aeec61c0f7fde93620cb02d60/configs/bsds/EDTER_BIMLA_320x320_80k_bsds_bs_8.py#L99
For example, *data = dict(samples_per_gpu=4)* means that each GPU can process 4 images.
Therefore, **the batch size of training = samples_per_gpu * GPU_NUM**. In the experiments, we set the training batch size to 8, where samples_per_gpu=4 and GPU_NUM=2.

The command to train the first-stage model is as follows
```shell
cd EDTER
bash ./tools/dist_train.sh ${CONFIG_FILE} ${GPU_NUM} 
# For example, train Stage I on the BSDS500 dataset with 2 GPUs
cd EDTER
bash ./tools/dist_train.sh configs/bsds/EDTER_BIMLA_320x320_80k_bsds_bs_8.py 2
```
### 2.2 Step2: The training of EDTER-Stage II on BSDS500
Change the '--global-model-path' in tools/train_local.py 
https://github.com/MengyangPu/EDTER/blob/ccb79b235e82ddbb4a6cc6d36c38325b674decd1/tools/train_local.py#L22-L23
```shell
cd EDTER
bash ./tools/dist_train_local.sh ${GLOBALCONFIG_FILE} ${CONFIG_FILE} ${GPU_NUM} 
# For example, train Stage II on the BSDS500 dataset with 2 GPUs
cd EDTER
bash ./tools/dist_train_local.sh configs/bsds/EDTER_BIMLA_320x320_80k_bsds_bs_8.py configs/bsds/EDTER_BIMLA_320x320_80k_bsds_local8x8_bs_8.py 2
```
### 2.3 How to train the EDTER model on BSDS-VOC (BSDS500 and PASCAL VOC Context):
### Step 1: The training of EDTER-VOC-Stage I on PASCAL VOC Context
We first pre-train Stage I on [PASCAL VOC Context Dataset](https://pan.baidu.com/s/1d9CTR9w1MTcVrBvG-WIIXw?pwd=83cv)
The command to train the first stage model on PASCAL VOC Context is as follows
```shell
cd EDTER
bash ./tools/dist_train.sh ${CONFIG_FILE} ${GPU_NUM} 
# For example, train Stage I on the PASCAL VOC Context dataset with 2 GPUs
cd EDTER
bash ./tools/dist_train.sh configs/bsds/EDTER_BIMLA_320x320_80k_pascal_bs_8.py 2
```
Note: The model trained on the PASCAL VOC Context dataset is used as the initialization model in Step2.

### 2.4 Step 2: The training of EDTER-VOC-Stage I on BSDS500
First, we set the path of the pre-training model in [train.py](https://github.com/MengyangPu/EDTER/blob/main/tools/train.py)
https://github.com/MengyangPu/EDTER/blob/3b1751abec5f0add6849393a9cbf2a8e73cc65f5/tools/train.py#L28-L30
For example, *parser.add_argument(
        '--load-from', type=str, default='../work_dirs/EDTER_BIMLA_320x320_80k_pascal_bs_8/iter_X0000.pth ',
        help='the checkpoint file to load weights from')*

Then, we execute the following command to train the first stage model on bsds500:
```shell
cd EDTER
bash ./tools/dist_train.sh ${CONFIG_FILE} ${GPU_NUM} 
# For example, train Stage I on the BSDS500 dataset with 2 GPUs
cd EDTER
bash ./tools/dist_train.sh configs/bsds/EDTER_BIMLA_320x320_80k_bsds_aug_bs_8.py 2
```
### 2.5 Step3: The training of EDTER-VOC-Stage II on BSDS500
Change the '--global-model-path' in [train_local.py](https://github.com/MengyangPu/EDTER/blob/main/tools/train_local.py).
https://github.com/MengyangPu/EDTER/blob/ccb79b235e82ddbb4a6cc6d36c38325b674decd1/tools/train_local.py#L22-L23
Note: According to the results in stage one, we select the best model as the global model. 
Thus, we set:
*parser.add_argument('--global-model-path', type=str, default=' ../work_dirs/EDTER_BIMLA_320x320_80k_bsds_aug_bs_8/iter_X0000.pth',
                        help='the dir of the best global model').*

Then, the command to train the second stage model is as follows:
```shell
cd EDTER
./tools/dist_train_local.sh ${GLOBALCONFIG_FILE} ${CONFIG_FILE} ${GPU_NUM} 
# For example, train Stage II on the BSDS500 dataset with 2 GPUs
cd EDTER
./tools/dist_train_local.sh configs/bsds/EDTER_BIMLA_320x320_80k_bsds_aug_bs_8.py configs/bsds/EDTER_BIMLA_320x320_80k_bsds_aug_local8x8_bs_8.py 2
```

## 3 Testing
### 3.1 EDTER-Stage I with single-scale testing
First, please set the '--config', '--checkpoint', and '--tmpdir' in [test.py](https://github.com/MengyangPu/EDTER/blob/main/tools/test.py).

'--config':
https://github.com/MengyangPu/EDTER/blob/3b1751abec5f0add6849393a9cbf2a8e73cc65f5/tools/test.py#L21
'--checkpoint':
https://github.com/MengyangPu/EDTER/blob/3b1751abec5f0add6849393a9cbf2a8e73cc65f5/tools/test.py#L22
'--tmpdir':
https://github.com/MengyangPu/EDTER/blob/f060fd3c8bf1e5b1c91097721b2eafecc5f3041e/tools/test.py#L47-L50
For example:
```
#If you want to test EDTER-Stage I, please set:
parser.add_argument('--config', type=str, default='configs/bsds/EDTER_BIMLA_320x320_80k_bsds_bs_8.py', help='train config file path')
parser.add_argument('--checkpoint', type=str, default='../work_dirs/EDTER_BIMLA_320x320_80k_bsds_bs_8/iter_XXXXX.pth')
#If you want to test EDTER-VOC-Stage I, please set:
parser.add_argument('--config', type=str, default='configs/bsds/EDTER_BIMLA_320x320_80k_bsds_aug_bs_8.py', help='train config file path')
parser.add_argument('--checkpoint', type=str, default='../work_dirs/EDTER_BIMLA_320x320_80k_bsds_aug_bs_8/iter_XXXXX.pth')
```
Then, please execute the command:
```shell
cd EDTER
python ./tools/test.py
```
### 3.2 EDTER-Stage I with multi-scale testing
First, please set the '--config', '--checkpoint', and '--tmpdir' in [test.py](https://github.com/MengyangPu/EDTER/blob/main/tools/test.py).

'--config':
https://github.com/MengyangPu/EDTER/blob/3b1751abec5f0add6849393a9cbf2a8e73cc65f5/tools/test.py#L21
'--checkpoint':
https://github.com/MengyangPu/EDTER/blob/3b1751abec5f0add6849393a9cbf2a8e73cc65f5/tools/test.py#L22
'--tmpdir':
https://github.com/MengyangPu/EDTER/blob/f060fd3c8bf1e5b1c91097721b2eafecc5f3041e/tools/test.py#L47-L50
For example:
```
#If you want to test EDTER-Stage I, please set:
parser.add_argument('--config', type=str, default='configs/bsds/EDTER_BIMLA_320x320_80k_bsds_bs_8_ms.py', help='train config file path')
parser.add_argument('--checkpoint', type=str, default='../work_dirs/EDTER_BIMLA_320x320_80k_bsds_bs_8/iter_XXXXX.pth')
#If you want to test EDTER-VOC-Stage I, please set:
parser.add_argument('--config', type=str, default='configs/bsds/EDTER_BIMLA_320x320_80k_bsds_aug_bs_8_ms.py', help='train config file path')
parser.add_argument('--checkpoint', type=str, default='../work_dirs/EDTER_BIMLA_320x320_80k_bsds_aug_bs_8/iter_XXXXX.pth')
```
Note: Use the config file ending in **_ms.py** in **configs/EDTER**.

Then, please execute the command:
```shell
cd EDTER
python ./tools/test.py
```

### 3.3 EDTER-Stage II with single-scale testing
First, please set the '--globalconfig', '--config', '--global-checkpoint', '--checkpoint', and '--tmpdir' in [test_local.py](https://github.com/MengyangPu/EDTER/blob/main/tools/test_local.py).

'--globalconfig':
https://github.com/MengyangPu/EDTER/blob/84cc7355c9012a7d31cd14e25fd6c6b336714163/tools/test_local.py#L20-L21
'--config':
https://github.com/MengyangPu/EDTER/blob/84cc7355c9012a7d31cd14e25fd6c6b336714163/tools/test_local.py#L22-L23
'--checkpoint':
https://github.com/MengyangPu/EDTER/blob/3b1751abec5f0add6849393a9cbf2a8e73cc65f5/tools/test_local.py#L24-L25
'--global-checkpoint':
https://github.com/MengyangPu/EDTER/blob/3b1751abec5f0add6849393a9cbf2a8e73cc65f5/tools/test_local.py#L26-L28
'--tmpdir':
https://github.com/MengyangPu/EDTER/blob/3b1751abec5f0add6849393a9cbf2a8e73cc65f5/tools/test_local.py#L53-L56

For example:
```
#If you want to test EDTER-Stage II, please set:
parser.add_argument('--globalconfig', type=str, default='configs/bsds/**EDTER_BIMLA_320x320_80k_bsds_bs_8.py**', help='train global config file path')
parser.add_argument('--config', type=str, default='configs/bsds/**EDTER_BIMLA_320x320_80k_bsds_local8x8_bs_8.py**', help='train local config file path')
parser.add_argument('--checkpoint', type=str, default='../work_dirs/EDTER_BIMLA_320x320_80k_bsds_local8x8_bs_8/iter_XXXXX.pth', help='the dir of local model')
parser.add_argument('--global-checkpoint', type=str, default='../work_dirs/EDTER_BIMLA_320x320_80k_bsds_bs_8/iter_XXXXX.pth', help='the dir of global model')
#If you want to test EDTER-VOC-Stage II, please set:
parser.add_argument('--globalconfig', type=str, default='configs/bsds/**EDTER_BIMLA_320x320_80k_bsds_aug_bs_8.py**', help='train global config file path')
parser.add_argument('--config', type=str, default='configs/bsds/**EDTER_BIMLA_320x320_80k_bsds_aug_local8x8_bs_8.py**', help='train local config file path')
parser.add_argument('--checkpoint', type=str, default='../work_dirs/EDTER_BIMLA_320x320_80k_bsds_aug_local8x8_bs_8/iter_XXXXX.pth', help='the dir of local model')
parser.add_argument('--global-checkpoint', type=str, default='../work_dirs/EDTER_BIMLA_320x320_80k_bsds_aug_bs_8/iter_XXXXX.pth', help='the dir of global model')
```
Please execute the command:
```shell
cd EDTER
python ./tools/test_local.py
```

### 3.4 EDTER-Stage II with multi-scale testing
First, please set the '--globalconfig', '--config', '--global-checkpoint', '--checkpoint', and '--tmpdir' in [test_local.py](https://github.com/MengyangPu/EDTER/blob/main/tools/test_local.py).

'--globalconfig':
https://github.com/MengyangPu/EDTER/blob/84cc7355c9012a7d31cd14e25fd6c6b336714163/tools/test_local.py#L20-L21
'--config':
https://github.com/MengyangPu/EDTER/blob/84cc7355c9012a7d31cd14e25fd6c6b336714163/tools/test_local.py#L22-L23
'--checkpoint':
https://github.com/MengyangPu/EDTER/blob/3b1751abec5f0add6849393a9cbf2a8e73cc65f5/tools/test_local.py#L24-L25
'--global-checkpoint':
https://github.com/MengyangPu/EDTER/blob/3b1751abec5f0add6849393a9cbf2a8e73cc65f5/tools/test_local.py#L26-L28
'--tmpdir':
https://github.com/MengyangPu/EDTER/blob/3b1751abec5f0add6849393a9cbf2a8e73cc65f5/tools/test_local.py#L53-L56

For example:
```
#If you want to test EDTER-Stage II, please set:
parser.add_argument('--globalconfig', type=str, default='configs/bsds/**EDTER_BIMLA_320x320_80k_bsds_bs_8_ms.py**', help='train global config file path')
parser.add_argument('--config', type=str, default='configs/bsds/**EDTER_BIMLA_320x320_80k_bsds_local8x8_bs_8_ms.py**', help='train local config file path')
parser.add_argument('--checkpoint', type=str, default='../work_dirs/EDTER_BIMLA_320x320_80k_bsds_aug_local8x8_bs_8/iter_XXXXX.pth', help='the dir of local model')
parser.add_argument('--global-checkpoint', type=str, default='../work_dirs/EDTER_BIMLA_320x320_80k_bsds_aug_bs_8/iter_XXXXX.pth', help='the dir of global model')
#If you want to test EDTER-VOC-Stage II, please set:
parser.add_argument('--globalconfig', type=str, default='configs/bsds/**EDTER_BIMLA_320x320_80k_bsds_aug_bs_8_ms.py**', help='train global config file path')
parser.add_argument('--config', type=str, default='configs/bsds/**EDTER_BIMLA_320x320_80k_bsds_aug_local8x8_bs_8_ms.py**', help='train local config file path')
parser.add_argument('--checkpoint', type=str, default='../work_dirs/EDTER_BIMLA_320x320_80k_bsds_aug_local8x8_bs_8/iter_XXXXX.pth', help='the dir of local model')
parser.add_argument('--global-checkpoint', type=str, default='../work_dirs/EDTER_BIMLA_320x320_80k_bsds_aug_bs_8/iter_XXXXX.pth', help='the dir of global model')
```
Note: Use the config file ending in **_ms.py** in **configs/EDTER**.

Please execute the command:
```shell
cd EDTER
python ./tools/test_local.py
```
## ðŸ”¥ðŸ”¥4 The original results v.s. The reproduced resultsðŸ”¥ðŸ”¥
### 4.1 The results of EDTER-Stage I on BSDS500
The **original results** reported in the [paper](https://arxiv.org/abs/2203.08566) (row 1 of Table 2) are as:
|   Model    | ODS  | OIS  | AP   |
| -----------| ---- | ---- | ---- |
|ðŸ”¥EDTER-StageI(SS)|0.817 |0.835 |0.867 |

The **reproduced results** of EDTER-Stage I on BSDS500 are shown in the table:
|   iter   | ODS(SS)  | OIS(SS)  | AP(SS)   | ODS(MS)  | OIS(MS)  | AP(MS)   |
| ---------| ---- | ---- | ---- | ---- | ---- | ---- |
| 10k	   |0.813 |	0.830|0.861	|0.837 |0.854 | 0.890|
| 20k	   |0.816 |	0.832|0.865	|0.837 |0.853 |	0.889|
|**ðŸ”¥30k(best)**   |**0.817**|**0.833**|**0.866**|**0.837**|**0.853**|**0.888**|
| 40k	   |0.815 |	0.832|0.866	|0.836 |0.853 |	0.888|
| 50k	   |0.815 |	0.832|0.866	|0.834 |0.852 |	0.887|
| 60k	   |0.813 |	0.828|0.862	|0.832 |0.849 |	0.885|
| 70k	   |0.813 |	0.829|0.864	|0.832 |0.849 |	0.884|
| 80k	   |0.813 |	0.829|0.863	|0.831 |0.849 |	0.884|

**SS: Single-Scale testing, MS: Multi-Scale testing**

**ðŸ”¥All files generated during the training process, including the models and test results (.png and .mat files) for every 10k iterations, and the training logs can be downloaded through [BaiDuNetdisk](https://pan.baidu.com/s/158B9xct-J8nnOBGSPuotRA?pwd=nx35).**

### 4.2 The results of EDTER-Stage II on BSDS500
The **original results** reported in the [paper](https://arxiv.org/abs/2203.08566) (Table 3, EDTER) are as:
|    Model    | ODS(SS)  | OIS(SS)  | AP(SS)   | ODS(MS)  | OIS(MS)  | AP(MS)   |
| ------------| ---- | ---- | ---- | ---- | ---- | ---- |
|ðŸ”¥EDTER-StageII|0.824 |0.841 |0.880 |0.840 |0.858 |0.896 |

The **reproduced results** of EDTER-Stage II on BSDS500 are shown in the table:
|   iter   | ODS(SS)  | OIS(SS)  | AP(SS)   | ODS(MS)  | OIS(MS)  | AP(MS)   |
| ---------| ---- | ---- | ---- | ---- | ---- | ---- |
| 10k	   |0.821 |0.838 |0.874 |0.839 |0.856 |0.893 |
| 20k	   |0.822 |0.839 |0.876 |0.838 |0.856 |0.893 |
| 30k	   |0.824 |0.841 |0.878 |0.837 |0.855 |0.893 |
|**ðŸ”¥40k(best)**   |**0.825**|**0.841**|**0.880**|**0.838**|**0.855**|**0.894**|
| 50k	   |0.823 |0.840 |0.877 |0.835 |0.852 |0.892 |
| 60k	   |0.822 |0.839 |0.876 |0.834 |0.852 |0.889 |
| 70k	   |0.820 |0.837 |0.875 |0.833 |0.851 |0.890 |
| 80k	   |0.817 |0.836 |0.873 |0.829 |0.848 |0.888 |

**ðŸ”¥All files generated during the training process, including the models and test results (.png and .mat files) for every 10k iterations, and the training logs can be downloaded through [BaiDuNetdisk](https://pan.baidu.com/s/1JzlXAH8YnOEFiDncjSDZpA?pwd=mawm).**


### 4.3 The EDTER model pre-trained on the PASCAL VOC Context dataset
On the testing set of BSDS500, we report the results of **the EDTER model pre-trained on the PASCAL VOC Context dataset**, as shown in the table:
|   iter   | ODS(SS)  | OIS(SS)  | AP(SS)   |
| ---------| ---- | ---- | ---- |
| **ðŸ”¥10k(best)**  |**0.775** |**0.795** |**0.835** |
| 20k      |0.767 |0.788 |0.827 |
| 30k	   |0.760 |0.777 |0.816 |
| 40k      |0.762 |0.779 |0.815 |
| 50k	   |0.755 |0.769 |0.809 |
| 60k	   |0.757 |0.771 |0.810 |
| 70k	   |0.757 |0.771 |0.810 |
| 80k	   |0.757 |0.771 |0.810 |

**ðŸ”¥All files generated during the training process, including the models and test results (.png and .mat files) for every 10k iterations, and the training logs can be downloaded through [BaiDuNetdisk](https://pan.baidu.com/s/1SS62jBW-Qao7BQ3nXrDvYQ?pwd=dk5v).**


### 4.4 The results of EDTER-VOC-Stage I on BSDS500
The **original results** reported in the [paper](https://arxiv.org/abs/2203.08566) are **null**.

The **reproduced results** of EDTER-VOC-Stage I on BSDS500 are shown in the table:
|   iter   | ODS(SS)  | OIS(SS)  | AP(SS)   | ODS(MS)  | OIS(MS)  | AP(MS)   |
| ---------| ---- | ---- | ---- | ---- | ---- | ---- |
| 10k	   |0.823 |0.837 |0.871 |0.845 |0.861 |0.897 |
|**ðŸ”¥20k(best)**   |**0.824** |**0.839** |**0.872** |**0.844** |**0.860** |**0.896** |
| 30k	   |0.822 |0.838 |0.873 |0.842 |0.858 |0.895 |
| 40k      |0.821 |0.837 |0.871 |0.842 |0.857 |0.893 |
| 50k	   |0.821 |0.836 |0.870 |0.839 |0.855 |0.891 |
| 60k	   |0.820 |0.834 |0.869 |0.840 |0.855 |0.891 |
| 70k	   |0.819 |0.835 |0.869 |0.838 |0.854 |0.890 |
| 80k	   |0.819 |0.834 |0.868 |0.838 |0.854 |0.890 |

**ðŸ”¥All files generated during the training process, including the models and test results (.png and .mat files) for every 10k iterations, and the training logs can be downloaded through [BaiDuNetdisk](https://pan.baidu.com/s/15CIuL2r0fZckSifgNFanBw?pwd=iwwv).**

### 4.5 The results of EDTER-VOC-Stage II on BSDS500
The **original results** reported in the [paper](https://arxiv.org/abs/2203.08566) (Table 3, EDTER-VOC) are as:
|    Model    | ODS(SS)  | OIS(SS)  | AP(SS)   | ODS(MS)  | OIS(MS)  | AP(MS)   |
| ------------| ---- | ---- | ---- | ---- | ---- | ---- |
|ðŸ”¥EDTER-VOC-Stage II|0.832 |0.847 |0.886 |0.848 |0.865 |0.906 |

The **reproduced results** of EDTER-VOC-Stage II on BSDS500 are shown in the table:
|   iter   | ODS(SS)  | OIS(SS)  | AP(SS)   | ODS(MS)  | OIS(MS)  | AP(MS)   |
| ---------| ---- | ---- | ---- | ---- | ---- | ---- |
| 10k	   |0.827 |0.844 |0.880 |0.846 |0.861 |0.900 |
|**ðŸ”¥20k(best)**   |**0.829** |**0.845** |**0.883** |**0.846** |**0.862** |**0.901** |
| 30k	   |0.829 |0.845 |0.883 |0.843 |0.860 |0.899 |
| 40k      |0.826 |0.842 |0.882 |0.841 |0.858 |0.897 |
| 50k	   |0.823 |0.838 |0.878 |0.837 |0.854 |0.893 |
| 60k	   |0.821 |0.837 |0.878 |0.834 |0.852 |0.892 |
| 70k	   |0.816 |0.833 |0.872 |0.831 |0.848 |0.888 |
| 80k	   |0.815 |0.832 |0.871 |0.830 |0.848 |0.887 |

**ðŸ”¥All files generated during the training process, including the models and test results (.png and .mat files) for every 10k iterations, and the training logs can be downloaded through [BaiDuNetdisk](https://pan.baidu.com/s/1LmgQiCiWKrwzEuog5BQ_ng?pwd=b9rm).**


## 5 [Eval](https://github.com/MengyangPu/EDTER/tree/main/eval)
#### BSDS500
```shell
cd eval
run eval_bsds.m
```
#### NYUD
Download the matfile(NYUD) from [here](https://pan.baidu.com/s/1LEeoOKkzdcewmPhq5z86wA)(Code:25p8).<br/>
```shell
cd eval
run eval_nyud.m
```

## 6 Results
If you want to compare your method with EDTER, you can download the precomputed results [BSDS500](https://drive.google.com/file/d/1zL74whvVnrZAe-j2BveLD1yZrsrk-Vb5/view?usp=sharing) and [NYUD](https://pan.baidu.com/s/1xy5JOqs_zLpOoTOlzb5Bxw)(code:b941).

## 7 Download Pre-trained model

| model                                            | Pre-trained Model                                                              |
| ------------------------------------------------ | ------------------------------------------------------------------------------ | 
|[EDTER-BSDS-VOC-StageI](configs/bsds/EDTER_BIMLA_320x320_80k_bsds_aug_bs_8.py/)           | [BaiDuNetdisk](https://pan.baidu.com/s/1xxkDRUoy9vfO6rtjx_GOqA)  (Code:l282) or [Google Drive](https://drive.google.com/drive/folders/1OkdakKKIMRGnKH8mxuFi_qI9sa903CD2?usp=share_link)|
|[EDTER-BSDS-VOC-StageII](configs/bsds/EDTER_BIMLA_320x320_80k_bsds_aug_local8x8_bs_8.py/)          | [BaiDuNetdisk](https://pan.baidu.com/s/1hT1v24H6GjjjjMXqe_Knuw)  (Code:skjw) or [Google Drive](https://drive.google.com/drive/folders/1OkdakKKIMRGnKH8mxuFi_qI9sa903CD2?usp=share_link)|
|[EDTER-NYUD-RGB-StageI](configs/nyud/EDTER_BIMLA_320x320_40k_nyud_rgb_bs_4.py/)          | [BaiDuNetdisk](https://pan.baidu.com/s/1nkBuXV1s4YUpkmu-7eYV-w)  (Code:dwdi)  |
|[EDTER-NYUD-RGB-StageII](configs/nyud/EDTER_BIMLA_320x320_40k_nyud_rgb_local8x8_bs_4.py/)          | [BaiDuNetdisk](https://pan.baidu.com/s/1ihUbPeVr5cRt_vef4pkBZQ)  (Code:s00u)  |
|[EDTER-NYUD-HHA-StageI](configs/nyud/EDTER_BIMLA_320x320_40k_nyud_hha_bs_4.py/)          | [BaiDuNetdisk](https://pan.baidu.com/s/1xzPela1UYTNa9Mdk-i_G-A)  (Code:ko2f)  |
|[EDTER-NYUD-HHA-StageII](configs/nyud/EDTER_BIMLA_320x320_40k_nyud_hha_local8x8_bs_4.py/)          | [BaiDuNetdisk](https://pan.baidu.com/s/1huMD4Ecop6ACrK1O4VToNA)  (Code:p7wu)  |

## 8 Important notes
- All the models are trained and tested on a single machine with multiple NVIDIA-V100-32G GPUs.
- Training on distributed GPUs is not supported.

## 9 Acknowledgments
- We thank the anonymous reviewers for valuable and inspiring comments and suggestions.
- Thanks to the previous open-sourced repo:<br/>
  [SETR](https://github.com/fudan-zvg/SETR)<br/>
  [MMsegmentation](https://github.com/open-mmlab/mmsegmentation)<br/>

## 10 Reference
```bibtex
@InProceedings{Pu_2022_CVPR,
    author    = {Pu, Mengyang and Huang, Yaping and Liu, Yuming and Guan, Qingji and Ling, Haibin},
    title     = {EDTER: Edge Detection With Transformer},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {1402-1412}
}
```
